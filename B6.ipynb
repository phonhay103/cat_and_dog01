{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XHbZdgACnBKO4bAWZNg2rtD8mmc0k_l6",
      "authorship_tag": "ABX9TyNgRJJvZB8OWSOo0CAHPV7W"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjpOxE7Kbk35"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test.is_gpu_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7QAJBOpLc2k"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9mXkNm9NQ6Q"
      },
      "source": [
        "!wget -q --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\r\n",
        "!unzip -q horse-or-human.zip -d train_data\r\n",
        "!wget -q --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\r\n",
        "!unzip -q validation-horse-or-human.zip -d validation_data\r\n",
        "!wget -q --no-check-certificate https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQvtefxbN2Rg"
      },
      "source": [
        "local_weights_file = './inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXJpf0f5QE4h"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\r\n",
        "\r\n",
        "pre_trained_model = InceptionV3(input_shape = (300, 300, 3),\r\n",
        "                                include_top = False,\r\n",
        "                                weights = None)\r\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L51IOzdcQ-Po"
      },
      "source": [
        "for layer in pre_trained_model.layers:\r\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUWB38bNRi9j"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\r\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OaUVjBcSzH9"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "\r\n",
        "new_layers = layers.Flatten()(last_output)\r\n",
        "new_layers = layers.Dense(1024, activation='relu')(new_layers)\r\n",
        "new_layers = layers.Dropout(0.2)(new_layers)\r\n",
        "new_layers = layers.Dense(1, activation='sigmoid')(new_layers)\r\n",
        "\r\n",
        "model = Model(pre_trained_model.input, new_layers)\r\n",
        "model.compile(optimizer = RMSprop(lr=0.001),\r\n",
        "              loss = 'binary_crossentropy',\r\n",
        "              metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqKWoTypWuyP"
      },
      "source": [
        "train_folder = './train_data'\r\n",
        "valid_folder = './validation_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQBx2L9oXe5X"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "train_data_gen = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                    rotation_range = 40,\r\n",
        "                                    width_shift_range = 0.2,\r\n",
        "                                    height_shift_range = 0.2,\r\n",
        "                                    shear_range = 0.2,\r\n",
        "                                    zoom_range = 0.2,\r\n",
        "                                    horizontal_flip = True)\r\n",
        "# Validation data should not be augmented\r\n",
        "valid_data_gen = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator = train_data_gen.flow_from_directory(train_folder,\r\n",
        "                                                     batch_size = 20,\r\n",
        "                                                     class_mode = 'binary',\r\n",
        "                                                     target_size = (300, 300))\r\n",
        "\r\n",
        "valid_generator = valid_data_gen.flow_from_directory(valid_folder,\r\n",
        "                                                     batch_size = 20,\r\n",
        "                                                     class_mode = 'binary',\r\n",
        "                                                     target_size = (300, 300))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyal2nK3Y9Ii"
      },
      "source": [
        "history = model.fit_generator(\r\n",
        "        generator = train_generator,\r\n",
        "        validation_data = valid_generator,\r\n",
        "        steps_per_epoch = 32,\r\n",
        "        epochs = 20,\r\n",
        "        validation_steps = 8,\r\n",
        "        verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQSJCxfdbEhV"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#-----------------------------------------------------------\r\n",
        "# Retrieve a list of list results on training and test data\r\n",
        "# sets for each training epoch\r\n",
        "#-----------------------------------------------------------\r\n",
        "acc      = history.history[     'acc' ]\r\n",
        "val_acc  = history.history[ 'val_acc' ]\r\n",
        "loss     = history.history[    'loss' ]\r\n",
        "val_loss = history.history['val_loss' ]\r\n",
        "\r\n",
        "epochs   = range(len(acc)) # Get number of epochs\r\n",
        "\r\n",
        "#------------------------------------------------\r\n",
        "# Plot training and validation accuracy per epoch\r\n",
        "#------------------------------------------------\r\n",
        "plt.plot  ( epochs,     acc )\r\n",
        "plt.plot  ( epochs, val_acc )\r\n",
        "plt.title ('Training and validation accuracy')\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "#------------------------------------------------\r\n",
        "# Plot training and validation loss per epoch\r\n",
        "#------------------------------------------------\r\n",
        "plt.plot  ( epochs,     loss )\r\n",
        "plt.plot  ( epochs, val_loss )\r\n",
        "plt.title ('Training and validation loss'   )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}